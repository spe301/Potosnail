{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from potosnail import MachineLearning, DeepLearning, DataHelper, Evaluater, Algorithms, Wrappers\n",
    "from sklearn.datasets import load_boston #loading boston housing data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# class instantiations\n",
    "ml = MachineLearning()\n",
    "dl = DeepLearning()\n",
    "dh = DataHelper()\n",
    "ev = Evaluater()\n",
    "al = Algorithms()\n",
    "wr = Wrappers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(load_boston()['data'])\n",
    "df.columns = list(load_boston()['feature_names'])\n",
    "df['price'] = load_boston()['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard scaling data for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "          7         8         9        10        11        12  price  \n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562   24.0  \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439   21.6  \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727   34.7  \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517   33.4  \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501   36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = dh.ScaleData('standard', df.drop(['price'], axis='columns'))\n",
    "df2['price'] = df['price']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = dh.HoldOut(df2) # using HoldOut function\n",
    "X = train.drop(['price'], axis='columns')\n",
    "Xval = test.drop(['price'], axis='columns')\n",
    "y = train['price']\n",
    "yval = test['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CompareModels function to pick the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lin</td>\n",
       "      <td>0.777797</td>\n",
       "      <td>0.675678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.829683</td>\n",
       "      <td>0.722897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.980015</td>\n",
       "      <td>0.731333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AB</td>\n",
       "      <td>0.919079</td>\n",
       "      <td>0.742624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GB</td>\n",
       "      <td>0.982691</td>\n",
       "      <td>0.802530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.775410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.655584</td>\n",
       "      <td>0.583854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  train_acc  test_acc\n",
       "0   Lin   0.777797  0.675678\n",
       "1   KNN   0.829683  0.722897\n",
       "2    DT   1.000000  0.617578\n",
       "3    RF   0.980015  0.731333\n",
       "4    AB   0.919079  0.742624\n",
       "5    GB   0.982691  0.802530\n",
       "6   XGB   0.999998  0.775410\n",
       "7   SVM   0.655584  0.583854"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.CompareModels(X, y, 'regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to Optimize a model!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go with XGB, XGBRegressor :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 99 candidates, totalling 297 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 99 candidates, totalling 297 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 274 out of 297 | elapsed:    6.6s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 297 out of 297 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:08:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { criterion } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "estimators = al.Estimators(X, 50) #returns a list of n_estimators for the gridsearch\n",
    "grid = {'learning_rate': [0.1, 0.5, 1], 'n_estimators': estimators, 'criterion': ['friedman_mse', 'mse', 'mae']}\n",
    "reg = ml.Optimize(XGBRegressor(), grid, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our n_estimators in case you're curious\n",
    "estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:09:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { criterion } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    predicted  actual     error     %error\n",
       " 0   29.071417    31.6  2.528583   8.001845\n",
       " 1   20.780781    22.4  1.619219   7.228657\n",
       " 2   19.669271    22.5  2.830729  12.581016\n",
       " 3   22.909016    22.8  0.109016   0.995241\n",
       " 4   24.614794    25.2  0.585206   2.322247\n",
       " 5   42.472900    39.8  2.672900   0.937068\n",
       " 6   20.488113    20.6  0.111887   0.543139\n",
       " 7   17.365139    16.1  1.265139   0.927145\n",
       " 8   27.598541    31.5  3.901459  12.385583\n",
       " 9   17.700581    23.7  5.999419  25.314006\n",
       " 10  11.042952    13.4  2.357048  17.589914\n",
       " 11  14.093417    13.5  0.593417   0.957894\n",
       " 12  20.199444    19.4  0.799444   0.960422\n",
       " 13  33.535133    33.4  0.135133   0.995970\n",
       " 14  19.969429    23.2  3.230571  13.924875\n",
       " 15  33.816280    35.4  1.583720   4.473784\n",
       " 16  21.942820    21.6  0.342820   0.984377\n",
       " 17  17.274258    20.0  2.725742  13.628712\n",
       " 18  41.299736    50.0  8.700264  17.400528\n",
       " 19  18.862793    18.8  0.062793   0.996671\n",
       " 20  19.981598    20.4  0.418402   2.050991\n",
       " 21  20.583384    22.2  1.616616   7.282056\n",
       " 22  21.148268    19.3  1.848268   0.912604\n",
       " 23  22.932470    24.5  1.567530   6.398080\n",
       " 24  17.558102    20.0  2.441898  12.209492\n",
       " 25  18.520046    17.5  1.020046   0.944922\n",
       " 26  22.443783    21.4  1.043783   0.953493\n",
       " 27  18.168598    17.8  0.368598   0.979712\n",
       " 28  22.229567    19.8  2.429567   0.890706\n",
       " 29  15.476667    15.6  0.123333   0.790594\n",
       " 30  17.447733    20.2  2.752267  13.625085\n",
       " 31  23.492323    23.1  0.392323   0.983300\n",
       " 32  28.351820    32.5  4.148180  12.763631\n",
       " 33  31.388905    34.7  3.311095   9.542062\n",
       " 34  21.656036    22.9  1.243964   5.432156\n",
       " 35  20.835197    17.4  3.435197   0.835125\n",
       " 36  31.002960    30.1  0.902960   0.970875\n",
       " 37  32.351929    33.0  0.648071   1.963852\n",
       " 38  33.510628    33.1  0.410628   0.987746\n",
       " 39  20.030954    19.5  0.530954   0.973493\n",
       " 40  20.086123    18.8  1.286123   0.935970\n",
       " 41  31.768833    31.6  0.168833   0.994686\n",
       " 42  19.057577    16.0  3.057577   0.839561\n",
       " 43  20.340303    21.4  1.059697   4.951853\n",
       " 44  20.769932    19.6  1.169932   0.943672\n",
       " 45  43.411499    46.7  3.288501   7.041758\n",
       " 46  19.600817    23.1  3.499183  15.147980\n",
       " 47  32.002968    29.6  2.402968   0.924914\n",
       " 48   8.952563     5.6  3.352563   0.625519\n",
       " 49  13.855204    13.3  0.555204   0.959928\n",
       " 50  18.417330    17.1  1.317330   0.928473,\n",
       " 6.068465065163799,\n",
       " 91.29)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.EvaluateRegressor(reg, X, Xval, y, yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE is 6.07, accuracy is 91.29% !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performance is good but let's use VifIt to check for multicolinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.781944\n",
       "1     2.441874\n",
       "2     4.321181\n",
       "3     1.093526\n",
       "4     4.428240\n",
       "5     2.016564\n",
       "6     3.436539\n",
       "7     4.104558\n",
       "8     7.641019\n",
       "9     9.583625\n",
       "10    1.816788\n",
       "11    1.360511\n",
       "12    3.132705\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh.VifIt(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We may do better without 'RAD' and 'Tax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sns.barplot(list(load_boston()['feature_names']), list(dh.VifIt(X)))\n",
    "plt.xlabel('feature')   \n",
    "plt.ylabel('Vif Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X and y will be changed because deep learning models take in np.arrays rather than dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X2 = np.array(X)\n",
    "Xv2 = np.array(Xval)\n",
    "y2 = np.array(y)\n",
    "yv2 = np.array(yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following can also be done with DeepLearning().FastNN(), just be sure to set task to 'regression' and output_dim to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 64 #first layer will have 64 nodes\n",
    "activation = 'relu'\n",
    "regularizer = 'L1' #used to prevent overfitting in neural networks\n",
    "stacking = True #our second layer will also have 64 nodes\n",
    "dropout = False # another solution to overfitting\n",
    "nlayers = 4 #the neural network will have 4 layers\n",
    "closer = False\n",
    "loss = 'mae' #we will use Mean Absolute Error loss function\n",
    "optimizer = 'rmsprop' #we will use Root Mean Squared Backpropagation for out optimization function\n",
    "y_col = 'price' #this parameter isn't actually used but CollectPreformance needs functions to take in 10 arguments\n",
    "model = dl.DeepTabularRegression(nodes, activation, regularizer, stacking, dropout, nlayers, closer, loss, optimizer, y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 21.2867 - val_loss: 18.4954\n",
      "Epoch 2/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 16.6019 - val_loss: 12.4922\n",
      "Epoch 3/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.0749 - val_loss: 6.8911\n",
      "Epoch 4/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.4939 - val_loss: 5.9222\n",
      "Epoch 5/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.8130 - val_loss: 4.9520\n",
      "Epoch 6/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.9128 - val_loss: 5.1229\n",
      "Epoch 7/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.0562 - val_loss: 4.6017\n",
      "Epoch 8/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.4994 - val_loss: 4.0382\n",
      "Epoch 9/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.4285 - val_loss: 3.9997\n",
      "Epoch 10/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.3132 - val_loss: 3.8678\n",
      "Epoch 11/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2473 - val_loss: 3.6965\n",
      "Epoch 12/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.3530 - val_loss: 3.9514\n",
      "Epoch 13/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2559 - val_loss: 3.5341\n",
      "Epoch 14/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.0404 - val_loss: 3.4612\n",
      "Epoch 15/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.1314 - val_loss: 4.0177\n",
      "Epoch 16/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.9449 - val_loss: 3.6066\n",
      "Epoch 17/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.0927 - val_loss: 3.3731\n",
      "Epoch 18/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.7865 - val_loss: 3.6662\n",
      "Epoch 19/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.6154 - val_loss: 3.8128\n",
      "Epoch 20/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.8841 - val_loss: 3.8121\n",
      "Epoch 21/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.8796 - val_loss: 3.1662\n",
      "Epoch 22/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7232 - val_loss: 3.0499\n",
      "Epoch 23/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.5521 - val_loss: 3.0962\n",
      "Epoch 24/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.7817 - val_loss: 3.1127\n",
      "Epoch 25/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6684 - val_loss: 3.0513\n",
      "Epoch 26/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7448 - val_loss: 3.1680\n",
      "Epoch 27/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6880 - val_loss: 3.1018\n",
      "Epoch 28/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6803 - val_loss: 3.0550\n",
      "Epoch 29/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7459 - val_loss: 3.0728\n",
      "Epoch 30/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.7086 - val_loss: 3.0255\n",
      "Epoch 31/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.7535 - val_loss: 3.5336\n",
      "Epoch 32/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7030 - val_loss: 3.3870\n",
      "Epoch 33/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6340 - val_loss: 3.3173\n",
      "Epoch 34/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.6989 - val_loss: 2.9399\n",
      "Epoch 35/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3145 - val_loss: 3.8544\n",
      "Epoch 36/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.5470 - val_loss: 3.0682\n",
      "Epoch 37/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4510 - val_loss: 2.8636\n",
      "Epoch 38/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4838 - val_loss: 3.1001\n",
      "Epoch 39/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4161 - val_loss: 2.9978\n",
      "Epoch 40/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3671 - val_loss: 2.9847\n",
      "Epoch 41/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4239 - val_loss: 2.8768\n",
      "Epoch 42/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.6308 - val_loss: 2.9451\n",
      "Epoch 43/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.5519 - val_loss: 2.8402\n",
      "Epoch 44/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4567 - val_loss: 2.7608\n",
      "Epoch 45/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3125 - val_loss: 2.7737\n",
      "Epoch 46/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4030 - val_loss: 3.1348\n",
      "Epoch 47/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3443 - val_loss: 2.9687\n",
      "Epoch 48/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4679 - val_loss: 3.0917\n",
      "Epoch 49/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.6737 - val_loss: 3.2046\n",
      "Epoch 50/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3981 - val_loss: 2.7423\n",
      "Epoch 51/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3385 - val_loss: 3.1044\n",
      "Epoch 52/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4973 - val_loss: 2.7305\n",
      "Epoch 53/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3269 - val_loss: 3.2464\n",
      "Epoch 54/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.7457 - val_loss: 2.8091\n",
      "Epoch 55/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.2135 - val_loss: 2.7069\n",
      "Epoch 56/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3567 - val_loss: 2.7234\n",
      "Epoch 57/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2949 - val_loss: 3.7471\n",
      "Epoch 58/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3196 - val_loss: 3.2167\n",
      "Epoch 59/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3836 - val_loss: 3.0977\n",
      "Epoch 60/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1956 - val_loss: 2.8659\n",
      "Epoch 61/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.2996 - val_loss: 3.0341\n",
      "Epoch 62/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3761 - val_loss: 2.7663\n",
      "Epoch 63/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3077 - val_loss: 2.8739\n",
      "Epoch 64/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.2157 - val_loss: 2.7369\n",
      "Epoch 65/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.1141 - val_loss: 2.5996\n",
      "Epoch 66/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2427 - val_loss: 2.6942\n",
      "Epoch 67/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.1035 - val_loss: 2.5642\n",
      "Epoch 68/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1581 - val_loss: 2.7539\n",
      "Epoch 69/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.1737 - val_loss: 2.9672\n",
      "Epoch 70/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3739 - val_loss: 2.7598\n",
      "Epoch 71/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2383 - val_loss: 3.0475\n",
      "Epoch 72/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3305 - val_loss: 2.6632\n",
      "Epoch 73/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1436 - val_loss: 3.4683\n",
      "Epoch 74/75\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.2567 - val_loss: 2.5820\n",
      "Epoch 75/75\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1514 - val_loss: 2.6915\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, batch_size=32, epochs=75, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 7,681\n",
      "Trainable params: 7,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ev.ViewLoss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for a fast and dirty approach with Wrapper().WrapML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "             gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None)\n",
      "Raw Vanilla\n",
      "RMSE = 18.826457457594064, Accuracy = 80.9%\n",
      "Fitting 3 folds for each of 396 candidates, totalling 1188 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 396 candidates, totalling 1188 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 598 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1188 out of 1188 | elapsed:   16.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data, Optimized Model\n",
      "RMSE = 13.635803414957818, Accuracy = 86.17%\n",
      "Fitting 3 folds for each of 396 candidates, totalling 1188 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 396 candidates, totalling 1188 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 598 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1188 out of 1188 | elapsed:   16.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is scaled with standard scaler, Model is optimized\n",
      "RMSE = 18.160912674281242, Accuracy = 81.58%\n",
      "Fitting 3 folds for each of 396 candidates, totalling 1188 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 396 candidates, totalling 1188 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 598 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1165 out of 1188 | elapsed:   15.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1188 out of 1188 | elapsed:   15.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is scaled with standard scaler and high vif features are removed. Model is optimized\n",
      "Using ['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'RAD', 'TAX', 'LSTAT'] as features\n",
      "RMSE = 27.631484351417974, Accuracy = 71.97%\n",
      "Fitting 3 folds for each of 396 candidates, totalling 1188 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 396 candidates, totalling 1188 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 598 tasks      | elapsed:    9.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is scaled with standard scaler and Smoted. Model is optimized\n",
      "Using ['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'LSTAT'] as features\n",
      "RMSE = 25.001730398584588, Accuracy = 74.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1188 out of 1188 | elapsed:   16.0s finished\n"
     ]
    }
   ],
   "source": [
    "model, df2, scaler, dim = wr.WrapML(df, 'price', 'regression', quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=9,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.5,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(scaler) #the model preformed best with the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns # the model preformed best with all 13 features as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
